{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Natural Language Processing\") \\\n",
    "   .config(\"spark.executor.memory\", \"6gb\") \\\n",
    "   .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('com.databricks.spark.csv')\\\n",
    "                    .options(header='true', inferschema='true')\\\n",
    "                    .load('TherapyBotSession.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------------+----+----+----+----+----+\n",
      "|response_id|      class|       response_text| _c3| _c4| _c5| _c6| _c7|\n",
      "+-----------+-----------+--------------------+----+----+----+----+----+\n",
      "| response_1|not_flagged|I try and avoid t...|null|null|null|null|null|\n",
      "| response_2|    flagged|Had a friend open...|null|null|null|null|null|\n",
      "| response_3|    flagged|I saved a girl fr...|null|null|null|null|null|\n",
      "| response_4|not_flagged|i cant think of o...|null|null|null|null|null|\n",
      "| response_5|not_flagged|\"Only really one ...|    |null|null|null|null|\n",
      "| response_6|not_flagged|a couple of years...|null|null|null|null|null|\n",
      "| response_7|    flagged|Roommate when he ...|null|null|null|null|null|\n",
      "| response_8|    flagged|i've had a couple...|null|null|null|null|null|\n",
      "| response_9|not_flagged|Listened to someo...|null|null|null|null|null|\n",
      "|response_10|    flagged|I will always lis...|null|null|null|null|null|\n",
      "|response_11|not_flagged|Took a week off w...|null|null|null|null|null|\n",
      "|response_12|    flagged|On the memorial a...|null|null|null|null|null|\n",
      "|response_13|not_flagged|Anxious girlfrien...|null|null|null|null|null|\n",
      "|response_14|not_flagged|               Never|null|null|null|null|null|\n",
      "|response_15|not_flagged|        You as a mom|null|null|null|null|null|\n",
      "|response_16|    flagged|ex gf was a cutte...|null|null|null|null|null|\n",
      "|response_17|not_flagged|I have helped adv...|null|null|null|null|null|\n",
      "|response_18|not_flagged|I've helped frien...|null|null|null|null|null|\n",
      "|response_19|not_flagged|A friend that is ...|null|null|null|null|null|\n",
      "|response_20|not_flagged|expressing concer...|null|null|null|null|null|\n",
      "+-----------+-----------+--------------------+----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('class', 'response_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|      class|       response_text|\n",
      "+-----------+--------------------+\n",
      "|not_flagged|I try and avoid t...|\n",
      "|    flagged|Had a friend open...|\n",
      "|    flagged|I saved a girl fr...|\n",
      "|not_flagged|i cant think of o...|\n",
      "|not_flagged|\"Only really one ...|\n",
      "|not_flagged|a couple of years...|\n",
      "|    flagged|Roommate when he ...|\n",
      "|    flagged|i've had a couple...|\n",
      "|not_flagged|Listened to someo...|\n",
      "|    flagged|I will always lis...|\n",
      "|not_flagged|Took a week off w...|\n",
      "|    flagged|On the memorial a...|\n",
      "|not_flagged|Anxious girlfrien...|\n",
      "|not_flagged|               Never|\n",
      "|not_flagged|        You as a mom|\n",
      "|    flagged|ex gf was a cutte...|\n",
      "|not_flagged|I have helped adv...|\n",
      "|not_flagged|I've helped frien...|\n",
      "|not_flagged|A friend that is ...|\n",
      "|not_flagged|expressing concer...|\n",
      "+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|      class|count|\n",
      "+-----------+-----+\n",
      "|not_flagged|   55|\n",
      "|    flagged|   25|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"class\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending = False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('word_count',F.size(F.split(F.col('response_text'),' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+\n",
      "|      class|       response_text|word_count|\n",
      "+-----------+--------------------+----------+\n",
      "|not_flagged|I try and avoid t...|         8|\n",
      "|    flagged|Had a friend open...|        25|\n",
      "|    flagged|I saved a girl fr...|        29|\n",
      "|not_flagged|i cant think of o...|        11|\n",
      "|not_flagged|\"Only really one ...|        74|\n",
      "|not_flagged|a couple of years...|        25|\n",
      "|    flagged|Roommate when he ...|        21|\n",
      "|    flagged|i've had a couple...|        38|\n",
      "|not_flagged|Listened to someo...|        13|\n",
      "|    flagged|I will always lis...|        41|\n",
      "|not_flagged|Took a week off w...|        60|\n",
      "|    flagged|On the memorial a...|        22|\n",
      "|not_flagged|Anxious girlfrien...|         6|\n",
      "|not_flagged|               Never|         1|\n",
      "|not_flagged|        You as a mom|         4|\n",
      "|    flagged|ex gf was a cutte...|        16|\n",
      "|not_flagged|I have helped adv...|        12|\n",
      "|not_flagged|I've helped frien...|         5|\n",
      "|not_flagged|A friend that is ...|        17|\n",
      "|not_flagged|expressing concer...|        21|\n",
      "+-----------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|      class|   avg_word_count|\n",
      "+-----------+-----------------+\n",
      "|    flagged|             50.6|\n",
      "|not_flagged|22.69090909090909|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('class')\\\n",
    "    .agg(F.avg('word_count').alias('avg_word_count'))\\\n",
    "    .orderBy('avg_word_count', ascending = False) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def sentiment_score(response_text):\n",
    "    try:\n",
    "        return TextBlob(response_text).sentiment.polarity\n",
    "    except:\n",
    "        return 'This is not working'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "sentiment_score_udf = F.udf(lambda x: sentiment_score(x), FloatType())\n",
    "df = df.select('class', 'response_text','word_count',\n",
    "                   sentiment_score_udf('response_text').alias('sentiment_score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+---------------+\n",
      "|      class|       response_text|word_count|sentiment_score|\n",
      "+-----------+--------------------+----------+---------------+\n",
      "|not_flagged|I try and avoid t...|         8|            0.0|\n",
      "|    flagged|Had a friend open...|        25|          -0.05|\n",
      "|    flagged|I saved a girl fr...|        29|          0.495|\n",
      "|not_flagged|i cant think of o...|        11|            0.0|\n",
      "|not_flagged|\"Only really one ...|        74|    0.036363635|\n",
      "|not_flagged|a couple of years...|        25|           -0.1|\n",
      "|    flagged|Roommate when he ...|        21|            0.0|\n",
      "|    flagged|i've had a couple...|        38|     0.16666667|\n",
      "|not_flagged|Listened to someo...|        13|            0.0|\n",
      "|    flagged|I will always lis...|        41|         -0.025|\n",
      "|not_flagged|Took a week off w...|        60|     0.16666667|\n",
      "|    flagged|On the memorial a...|        22|            0.0|\n",
      "|not_flagged|Anxious girlfrien...|         6|          -0.25|\n",
      "|not_flagged|               Never|         1|            0.0|\n",
      "|not_flagged|        You as a mom|         4|            0.0|\n",
      "|    flagged|ex gf was a cutte...|        16|           0.15|\n",
      "|not_flagged|I have helped adv...|        12|            0.0|\n",
      "|not_flagged|I've helped frien...|         5|            0.0|\n",
      "|not_flagged|A friend that is ...|        17|            0.5|\n",
      "|not_flagged|expressing concer...|        21|            0.0|\n",
      "+-----------+--------------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+\n",
      "|      class|avg_sentiment_score|\n",
      "+-----------+-------------------+\n",
      "|    flagged|0.09282141797244549|\n",
      "|not_flagged|0.03127356884493069|\n",
      "+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('class')\\\n",
    "    .agg(F.avg('sentiment_score').alias('avg_sentiment_score'))\\\n",
    "    .orderBy('avg_sentiment_score', ascending = False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+---------------+--------------------+\n",
      "|      class|       response_text|word_count|sentiment_score|               words|\n",
      "+-----------+--------------------+----------+---------------+--------------------+\n",
      "|not_flagged|I try and avoid t...|         8|            0.0|[I, try, and, avo...|\n",
      "|    flagged|Had a friend open...|        25|          -0.05|[Had, a, friend, ...|\n",
      "|    flagged|I saved a girl fr...|        29|          0.495|[I, saved, a, gir...|\n",
      "|not_flagged|i cant think of o...|        11|            0.0|[i, cant, think, ...|\n",
      "|not_flagged|\"Only really one ...|        74|    0.036363635|[\"Only, really, o...|\n",
      "|not_flagged|a couple of years...|        25|           -0.1|[a, couple, of, y...|\n",
      "|    flagged|Roommate when he ...|        21|            0.0|[Roommate, when, ...|\n",
      "|    flagged|i've had a couple...|        38|     0.16666667|[i've, had, a, co...|\n",
      "|not_flagged|Listened to someo...|        13|            0.0|[Listened, to, so...|\n",
      "|    flagged|I will always lis...|        41|         -0.025|[I, will, always,...|\n",
      "|not_flagged|Took a week off w...|        60|     0.16666667|[Took, a, week, o...|\n",
      "|    flagged|On the memorial a...|        22|            0.0|[On, the, memoria...|\n",
      "|not_flagged|Anxious girlfrien...|         6|          -0.25|[Anxious, girlfri...|\n",
      "|not_flagged|               Never|         1|            0.0|             [Never]|\n",
      "|not_flagged|        You as a mom|         4|            0.0|   [You, as, a, mom]|\n",
      "|    flagged|ex gf was a cutte...|        16|           0.15|[ex, gf, was, a, ...|\n",
      "|not_flagged|I have helped adv...|        12|            0.0|[I, have, helped,...|\n",
      "|not_flagged|I've helped frien...|         5|            0.0|[I've, helped, fr...|\n",
      "|not_flagged|A friend that is ...|        17|            0.5|[A, friend, that,...|\n",
      "|not_flagged|expressing concer...|        21|            0.0|[expressing, conc...|\n",
      "+-----------+--------------------+----------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('words',F.split(F.col('response_text'),' '))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = ['i','me','my','myself','we','our','ours','ourselves',\n",
    "              'you','your','yours','yourself','yourselves','he','him',\n",
    "              'his','himself','she','her','hers','herself','it','its',\n",
    "              'itself','they','them','their','theirs','themselves',\n",
    "              'what','which','who','whom','this','that','these','those',\n",
    "              'am','is','are','was','were','be','been','being','have',\n",
    "              'has','had','having','do','does','did','doing','a','an',\n",
    "              'the','and','but','if','or','because','as','until','while',\n",
    "              'of','at','by','for','with','about','against','between',\n",
    "              'into','through','during','before','after','above','below',\n",
    "              'to','from','up','down','in','out','on','off','over','under',\n",
    "              'again','further','then','once','here','there','when','where',\n",
    "              'why','how','all','any','both','each','few','more','most',\n",
    "              'other','some','such','no','nor','not','only','own','same',\n",
    "              'so','than','too','very','can','will','just','don','should','now']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsRemovalFeature = StopWordsRemover(inputCol=\"words\", \n",
    "                                           outputCol=\"words without stop\").setStopWords(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "stopWordRemovalPipeline = Pipeline(stages=[stopwordsRemovalFeature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+---------------+--------------------+--------------------+\n",
      "|      class|       response_text|word_count|sentiment_score|               words|  words without stop|\n",
      "+-----------+--------------------+----------+---------------+--------------------+--------------------+\n",
      "|not_flagged|I try and avoid t...|         8|            0.0|[I, try, and, avo...|[try, avoid, sort...|\n",
      "|    flagged|Had a friend open...|        25|          -0.05|[Had, a, friend, ...|[friend, open, me...|\n",
      "|    flagged|I saved a girl fr...|        29|          0.495|[I, saved, a, gir...|[saved, girl, sui...|\n",
      "|not_flagged|i cant think of o...|        11|            0.0|[i, cant, think, ...|[cant, think, one...|\n",
      "|not_flagged|\"Only really one ...|        74|    0.036363635|[\"Only, really, o...|[\"Only, really, o...|\n",
      "+-----------+--------------------+----------+---------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineFitRemoveStopWords = stopWordRemovalPipeline.fit(df)\n",
    "df = pipelineFitRemoveStopWords.transform(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = F.udf(lambda x: 1.0 if x == 'flagged' else 0.0, FloatType())\n",
    "df = df.withColumn('label', label('class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|      class|label|\n",
      "+-----------+-----+\n",
      "|not_flagged|  0.0|\n",
      "|    flagged|  1.0|\n",
      "|    flagged|  1.0|\n",
      "|not_flagged|  0.0|\n",
      "|not_flagged|  0.0|\n",
      "|not_flagged|  0.0|\n",
      "|    flagged|  1.0|\n",
      "|    flagged|  1.0|\n",
      "|not_flagged|  0.0|\n",
      "|    flagged|  1.0|\n",
      "|not_flagged|  0.0|\n",
      "|    flagged|  1.0|\n",
      "|not_flagged|  0.0|\n",
      "|not_flagged|  0.0|\n",
      "|not_flagged|  0.0|\n",
      "|    flagged|  1.0|\n",
      "|not_flagged|  0.0|\n",
      "|not_flagged|  0.0|\n",
      "|not_flagged|  0.0|\n",
      "|not_flagged|  0.0|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('class', 'label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.ml.feature as feat\n",
    "TF_ = feat.HashingTF(inputCol=\"words without stop\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "IDF_ = feat.IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipelineTFIDF = Pipeline(stages=[TF_, IDF_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit = pipelineTFIDF.fit(df)\n",
    "df = pipelineFit.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|         rawFeatures|            features|\n",
      "+-----+--------------------+--------------------+\n",
      "|  0.0|(10000,[4109,4159...|(10000,[4109,4159...|\n",
      "|  1.0|(10000,[2087,2801...|(10000,[2087,2801...|\n",
      "|  1.0|(10000,[399,828,1...|(10000,[399,828,1...|\n",
      "|  0.0|(10000,[1564,2044...|(10000,[1564,2044...|\n",
      "|  0.0|(10000,[60,232,52...|(10000,[60,232,52...|\n",
      "|  0.0|(10000,[618,696,1...|(10000,[618,696,1...|\n",
      "|  1.0|(10000,[482,903,1...|(10000,[482,903,1...|\n",
      "|  1.0|(10000,[264,821,8...|(10000,[264,821,8...|\n",
      "|  0.0|(10000,[3118,4260...|(10000,[3118,4260...|\n",
      "|  1.0|(10000,[76,230,10...|(10000,[76,230,10...|\n",
      "|  0.0|(10000,[87,230,11...|(10000,[87,230,11...|\n",
      "|  1.0|(10000,[695,1120,...|(10000,[695,1120,...|\n",
      "|  0.0|(10000,[1843,5666...|(10000,[1843,5666...|\n",
      "|  0.0|(10000,[2945],[1.0])|(10000,[2945],[3....|\n",
      "|  0.0|(10000,[5956],[1.0])|(10000,[5956],[3....|\n",
      "|  1.0|(10000,[274,828,1...|(10000,[274,828,1...|\n",
      "|  0.0|(10000,[1619,4255...|(10000,[1619,4255...|\n",
      "|  0.0|(10000,[4442,8878...|(10000,[4442,8878...|\n",
      "|  0.0|(10000,[941,1029,...|(10000,[941,1029,...|\n",
      "|  0.0|(10000,[810,4442,...|(10000,[810,4442,...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('label', 'rawFeatures','features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainingDF, testDF) = df.randomSplit([0.75, 0.25], seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logreg = LogisticRegression(regParam=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logregModel = logreg.fit(trainingDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionDF = logregModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+---+\n",
      "|label_prediction|0.0|1.0|\n",
      "+----------------+---+---+\n",
      "|             1.0|  2|  2|\n",
      "|             0.0| 12|  0|\n",
      "+----------------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionDF.crosstab('label', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "actual = predictionDF.select('label').toPandas()\n",
    "predicted = predictionDF.select('prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|              label|\n",
      "+-------+-------------------+\n",
      "|  count|                 16|\n",
      "|   mean|               0.25|\n",
      "| stddev|0.44721359549995804|\n",
      "|    min|                0.0|\n",
      "|    max|                1.0|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionDF.describe('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
